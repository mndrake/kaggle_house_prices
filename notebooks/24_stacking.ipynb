{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import fmin_cobyla\n",
    "from mlxtend.regressor import StackingRegressor, stacking_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline, BaseEstimator, TransformerMixin, FeatureUnion\n",
    "from sklearn.preprocessing import Imputer, KernelCenterer, StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    \n",
    "    y = np.log(train['SalePrice'].values)\n",
    "    ids_submission = test['Id'].values\n",
    "    \n",
    "    combined = train.append(test, ignore_index=True).drop(['SalePrice'], axis=1)\n",
    "    \n",
    "    ordered_levels = {\n",
    "        \"Alley\": [\"Grvl\", \"Pave\"],\n",
    "        \"BsmtCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\"],\n",
    "        \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "        \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "        \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "        \"BsmtQual\": [\"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"CentralAir\": [\"N\", \"Y\"],\n",
    "        \"Electrical\": [\"FuseP\", \"FuseF\", \"FuseA\", \"Mix\", \"SBrkr\"],\n",
    "        \"ExterCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"ExterQual\": [\"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "        \"FireplaceQu\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        'Functional': ['Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "        \"GarageCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n",
    "        \"GarageQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"HeatingQC\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"KitchenQual\": [\"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "        \"LotShape\": [\"IR3\", \"IR2\", \"IR1\", \"Reg\"],\n",
    "        \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "        \"PoolQC\": [\"Fa\", \"Gd\", \"Ex\"],\n",
    "        \"Street\": [\"Grvl\", \"Pave\"],   \n",
    "        \"Utilities\": [\"NoSeWa\", \"AllPub\"]\n",
    "    }\n",
    "    \n",
    "    for c in combined.columns:\n",
    "        if combined[c].dtype == 'object':\n",
    "            if c in ordered_levels:\n",
    "                combined[c] = combined[c].astype('category', categories = ordered_levels[c], ordered=True)\n",
    "            else:\n",
    "                combined[c] = combined[c].astype('category')\n",
    "                    \n",
    "    X = combined.iloc[:train.shape[0],:]\n",
    "    X_submission = combined.iloc[train.shape[0]:,:]\n",
    "    \n",
    "    return y, X, X_submission, ids_submission   \n",
    "\n",
    "y, X, X_submission, ids_submission = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RegressionBlend(BaseEstimator):\n",
    "    def __init__(self, regressors, scorer, n_folds=10):\n",
    "        self.regressors = regressors\n",
    "        self.n_folds = n_folds\n",
    "        self.scorer = scorer\n",
    "    \n",
    "    def __blended(self, p, x):\n",
    "        \"\"\"blend model results using weights(p)\"\"\"\n",
    "        result = None\n",
    "        for i in range(len(p)):\n",
    "            result = result + p[i] * x[i] if result is not None else p[i] * x[i]\n",
    "        result /= sum(p)\n",
    "        return result       \n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        def constraint(p, *args):\n",
    "            \"\"\"constrain to positive weights\"\"\"\n",
    "            return min(p) - .0    \n",
    "        def error(p, x, y):\n",
    "            \"\"\"error function to optimize\"\"\"\n",
    "            preds = self.__blended(p, x)\n",
    "            err = self.scorer(y, preds)\n",
    "            return err \n",
    "        preds = []\n",
    "        for regressor in self.regressors:\n",
    "            regressor.fit(X,y)\n",
    "            preds.append(cross_val_predict(regressor, X, y, cv=KFold(self.n_folds)))\n",
    "        # initial weights\n",
    "        p0 = np.ones(len(self.regressors))\n",
    "        p = fmin_cobyla(error, p0, args=(preds, y), cons=[constraint], rhoend=1e-5)\n",
    "        self.weights = [x/sum(p) for x in p]\n",
    "        blended_pred = self.__blended(p, preds)\n",
    "        self.score = rmse(y, blended_pred)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for regressor in self.regressors:\n",
    "            preds.append(regressor.predict(X))\n",
    "        return self.__blended(self.weights, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ProcessTreeData(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        \n",
    "        keep_columns = [\n",
    "            'Heating', 'ScreenPorch', 'PoolQC', 'CentralAir', \n",
    "            'HeatingQC', 'WoodDeckSF', 'PavedDrive', 'Exterior1st', \n",
    "            'PoolArea', 'TotalBsmtSF', 'BldgType', 'LotArea', 'YearBuilt', \n",
    "            'Neighborhood', 'MSZoning', 'SaleCondition', 'GrLivArea', \n",
    "            'OverallQual', 'OverallCond', 'BsmtUnfSF', 'BsmtExposure',\n",
    "            'Fireplaces', 'GarageArea','Condition1','FireplaceQu']\n",
    "        \n",
    "        _X.drop(list(set(X.columns) - set(keep_columns)), axis=1, inplace=True)\n",
    "        \n",
    "        if 'FireplaceQu' in X.columns:\n",
    "            _X[\"HasFireplace\"] = 1 - X[\"FireplaceQu\"].isnull() * 1\n",
    "                \n",
    "        for c in _X.columns:\n",
    "            if _X[c].dtype.name == 'category':\n",
    "                if _X[c].cat.ordered:\n",
    "                    _X[c] = _X[c].cat.codes\n",
    "                    \n",
    "        return pd.get_dummies(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ProcessLinearData(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "\n",
    "        keep_columns = [\n",
    "            'Heating', 'ScreenPorch', 'PoolQC', 'CentralAir', \n",
    "            'HeatingQC', 'WoodDeckSF', 'PavedDrive', 'Exterior1st', \n",
    "            'PoolArea', 'TotalBsmtSF', 'BldgType', 'LotArea', 'YearBuilt', \n",
    "            'Neighborhood', 'MSZoning', 'SaleCondition', 'GrLivArea', \n",
    "            'OverallQual', 'OverallCond', 'BsmtUnfSF', 'BsmtExposure',\n",
    "            'Fireplaces', 'GarageArea','Condition1','FireplaceQu']\n",
    "            \n",
    "        _X.drop(list(set(X.columns) - set(keep_columns)), axis=1, inplace=True)\n",
    "        \n",
    "        if 'FireplaceQu' in X.columns:\n",
    "            _X[\"HasFireplace\"] = 1 - X[\"FireplaceQu\"].isnull() * 1\n",
    "\n",
    "        for c in _X.columns:\n",
    "            if _X[c].dtype.name == 'category':\n",
    "                if _X[c].cat.ordered:\n",
    "                    _X[c] = _X[c].cat.codes\n",
    "                    \n",
    "        # skewed columns (>0.75)\n",
    "        for c in ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF2', '1stFlrSF', \n",
    "                  'GrLivArea', 'KitchenAbvGr', 'OpenPorchSF', 'PoolArea', 'MiscVal']:\n",
    "            if c in _X.columns:\n",
    "                _X[c] = np.log1p(X[c])\n",
    "                                            \n",
    "        return pd.get_dummies(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, column=None):\n",
    "        self.column = column\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        if self.columns is not None:\n",
    "            X.drop(self.columns, axis=1, inplace=True)\n",
    "        if self.column is not None:\n",
    "            X.drop([self.column], axis=1, inplace=True)                                            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KeepColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, column=None):\n",
    "        self.column = column\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        keep_columns = [] if self.columns is None else self.columns[:]\n",
    "        if self.column is not None:\n",
    "            keep_columns.append(self.column)\n",
    "        return X.select(lambda x: x in keep_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_xgb = make_pipeline(ProcessTreeData(),\n",
    "                          Imputer(strategy='most_frequent'),\n",
    "                          XGBRegressor(silent = True, \n",
    "                                       objective='reg:linear', \n",
    "                                       seed=1773,\n",
    "                                       max_depth=5,\n",
    "                                       nthread=8,\n",
    "                                       learning_rate=0.05,\n",
    "                                       n_estimators=500,\n",
    "                                       min_child_weight=1,\n",
    "                                       subsample=0.65,\n",
    "                                       colsample_bytree=0.65\n",
    "                                      ))\n",
    "\n",
    "model_gbm = make_pipeline(ProcessTreeData(),\n",
    "                          Imputer(strategy='most_frequent'),\n",
    "                          GradientBoostingRegressor(random_state=1773,\n",
    "                                                    learning_rate=0.1,\n",
    "                                                    max_depth=4,\n",
    "                                                    max_features=0.7,\n",
    "                                                    min_samples_leaf=1,\n",
    "                                                    n_estimators=250,\n",
    "                                                    subsample=0.75))\n",
    "\n",
    "model_et = make_pipeline(ProcessTreeData(),\n",
    "                         Imputer(strategy='most_frequent'),\n",
    "                         ExtraTreesRegressor(n_estimators=250,\n",
    "                                             max_depth=14, \n",
    "                                             n_jobs=8,\n",
    "                                             random_state=1773, \n",
    "                                             max_features=0.7))\n",
    "\n",
    "model_en = make_pipeline(ProcessLinearData(),\n",
    "                         Imputer(strategy='most_frequent'),\n",
    "                         StandardScaler(),\n",
    "                         PolynomialFeatures(interaction_only=True),\n",
    "                         ElasticNet(l1_ratio=0.4, alpha=0.0009, max_iter=5000))\n",
    "\n",
    "#metalearner = SVR(kernel='rbf')\n",
    "#metalearner = LinearRegression()\n",
    "\n",
    "model_stacked = RegressionBlend(regressors=[model_xgb, model_gbm, model_et, model_en], scorer=rmse, n_folds=)\n",
    "\n",
    "# model_stacked = StackingRegressor(regressors=[model_xgb, model_et, model_en], \n",
    "#                                   meta_regressor=metalearner)\n",
    "\n",
    "# model_stacked = StackingRegressor(regressors=[model_xgb, model_gbm, model_et, model_en], \n",
    "#                                   meta_regressor=metalearner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "folds = KFold(2, random_state=1773)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_stacked, \n",
    "                    #n_jobs=4,\n",
    "                    param_grid=params, \n",
    "                     #n_iter=60, \n",
    "                     #random_state=1773,\n",
    "                     scoring=make_scorer(rmse, greater_is_better=False), \n",
    "                     cv=folds,\n",
    "                     refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## new base -0.114874667872\n",
    "# base -0.115007\n",
    "## drop columns ##\n",
    "# 24\tFireplaceQu\t-0.115124\n",
    "# 21\tFireplaces\t-0.115966\n",
    "# 5\tWoodDeckSF\t-0.116229\n",
    "# 6\tPavedDrive\t-0.116352\n",
    "# 8\tPoolArea\t-0.116526\n",
    "# 10\tBldgType\t-0.116734\n",
    "# 1\tScreenPorch\t-0.116817\n",
    "# 2\tPoolQC\t-0.116853\n",
    "# 4\tHeatingQC\t-0.116921\n",
    "# 7\tExterior1st\t-0.116956\n",
    "# 0\tHeating\t-0.117091\n",
    "# 23\tCondition1\t-0.117285\n",
    "# 20\tBsmtExposure\t-0.117779\n",
    "# 3\tCentralAir\t-0.117933\n",
    "# 11\tLotArea\t-0.118374\n",
    "# 14\tMSZoning\t-0.118597\n",
    "# 13\tNeighborhood\t-0.118616\n",
    "# 22\tGarageArea\t-0.118815\n",
    "# 15\tSaleCondition\t-0.119013\n",
    "# 19\tBsmtUnfSF\t-0.120547\n",
    "# 17\tOverallQual\t-0.120855\n",
    "# 12\tYearBuilt\t-0.120858\n",
    "# 9\tTotalBsmtSF\t-0.122659\n",
    "# 18\tOverallCond\t-0.125446\n",
    "# 16\tGrLivArea\t-0.141893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 2.53 s, total: 2min 12s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressionBlend(n_folds=10,\n",
       "        regressors=[Pipeline(steps=[('processtreedata', ProcessTreeData()), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='most_frequent',\n",
       "    verbose=0)), ('xgbregressor', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.65,\n",
       "       gamma=0, learning_rate=0.05, ma...se, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])],\n",
       "        scorer=<function rmse at 0x11231d8c0>)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_stacked.fit(X,y)\n",
    "\n",
    "#                     #n_jobs=4,\n",
    "#                     param_grid=params, \n",
    "#                      #n_iter=60, \n",
    "#                      #random_state=1773,\n",
    "#                      scoring=make_scorer(rmse, greater_is_better=False), \n",
    "#                      cv=folds,\n",
    "#                      refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47423642905842228,\n",
       " 0.31768891292669066,\n",
       " 0.12204718348595336,\n",
       " 0.086027474528933751]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stacked.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: -0.122429658387\n",
      "CPU times: user 5min 47s, sys: 12.2 s, total: 5min 59s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X,y)\n",
    "print 'best score:', grid.best_score_\n",
    "# print 'best parameters:', grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21529208,  0.8514377 , -0.05355732])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({'params': [x['dropcolumn__column'] for x in grid.cv_results_['params']], \n",
    "#               'test_score': grid.cv_results_['mean_test_score']})\\\n",
    "#   .sort_values('test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_sub = grid.predict(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': ids_submission, 'SalePrice': np.exp(preds_sub)}).to_csv('../ensemble/models/stacked_sub_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof_preds(model, X, y, X_sub, n_folds=10, n_iter=1, seed=1234):\n",
    "    from random import Random\n",
    "    from scipy.stats import hmean\n",
    "    preds = np.zeros((np.shape(X)[0], n_iter))\n",
    "    preds_sub = np.zeros((np.shape(X_sub)[0], n_iter))\n",
    "    rng = Random(seed)\n",
    "    for i in range(n_iter):\n",
    "        rs = rng.randint(1,9999)\n",
    "        folds = KFold(n_folds, shuffle=True, random_state=rs)\n",
    "        preds_sub_j = np.zeros((np.shape(X_sub)[0], n_folds))\n",
    "        #print 'iter: {}'.format(i)\n",
    "        for j, (train_index, test_index) in enumerate(folds.split(X)):\n",
    "            if type(X) == pd.DataFrame:\n",
    "                X_train = X.iloc[train_index, :]\n",
    "                X_test = X.iloc[test_index, :]\n",
    "            else:\n",
    "                X_train = X[train_index, :]\n",
    "                X_test = X[test_index, :]                \n",
    "            y_train = y[train_index]\n",
    "            model.fit(X_train, y_train)\n",
    "            preds[test_index, i] = model.predict(X_test)\n",
    "            preds_sub_j[:,j] = model.predict(X_sub)\n",
    "        preds_sub[:, i] = hmean(np.clip(preds_sub_j, 1e-5, 14), axis=1)\n",
    "    return hmean(preds, axis=1), hmean(preds_sub, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_preds = get_oof_preds(model_stacked, X, y, X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': ids_submission, 'SalePrice': np.exp(sub_preds[1])}).to_csv('../ensemble/models/stacked_sub_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
